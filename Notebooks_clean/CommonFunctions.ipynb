{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "from mne import find_events\n",
    "from mne.decoding import Vectorizer, SlidingEstimator, cross_val_multiscore\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, StratifiedKFold, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, precision_recall_fscore_support, balanced_accuracy_score\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('TKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "#%matplotlib tk\n",
    "import pickle\n",
    "random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(s_id, sensors, fname, resampled=False):\n",
    "\n",
    "    if resampled == True:\n",
    "        epochs = mne.read_epochs(fname, verbose='error')\n",
    "        print(fname + ' loaded!')\n",
    "    else:\n",
    "        epochs = mne.read_epochs(fname, verbose='error')\n",
    "        resampleData(100, epochs, fname)\n",
    "    \n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleData(samplingRate, epochs, filename):\n",
    "    \n",
    "    epochs.resample(samplingRate, npad='auto')\n",
    "    fname = filename[:-4] + '_resampled.fif'\n",
    "    epochs.save(fname)\n",
    "    print(fname + ' loaded!')\n",
    "    return epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDataAndLabels(epochs, eventIdsList):\n",
    "    data, labels = [], []\n",
    "    \n",
    "    for l in eventIdsList:\n",
    "        # Check if given event exist in the data\n",
    "        if l in epochs.event_id:\n",
    "            # if it does, then get the data\n",
    "            epochs_tmp = epochs[l]\n",
    "            data_tmp = epochs_tmp.get_data()\n",
    "            #print(len(data_tmp))\n",
    "            data.append(data_tmp)\n",
    "            \n",
    "            # Extract labels: living --> label = 0 / object label = 1\n",
    "            if 'living' in l:\n",
    "                labels_tmp = np.zeros(data_tmp.shape[0])\n",
    "            else:\n",
    "                labels_tmp = np.ones(data_tmp.shape[0])\n",
    "\n",
    "            labels.append(labels_tmp)\n",
    "        else:\n",
    "            data.append([])\n",
    "            labels.append([])\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatNonEmpty(lists):\n",
    "    newList = []\n",
    "    for l in lists:\n",
    "        if len(l) > 0:\n",
    "            if len(newList) > 0:\n",
    "                newList = np.concatenate((newList, l))\n",
    "            else:\n",
    "                newList = l\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load confidence data\n",
    "def loadConfData(confFile):\n",
    "    conf = np.load(confFile, allow_pickle=True)\n",
    "    #Convert confidence values to int and None to -1 to ease their use\n",
    "    for i in range(len(conf)):\n",
    "        if conf[i] != None:\n",
    "            if len(conf[i]) > 0:\n",
    "                conf[i] = int(conf[i][0])\n",
    "            else:\n",
    "                conf[i] = 0\n",
    "        else:\n",
    "            conf[i] = -1\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitEpochs_byConfidence(confFile, epochs):\n",
    "    \n",
    "    # Load confidence ratings\n",
    "    conf = loadConfData(confFile)\n",
    "\n",
    "    #Extract the unique confidence values which are not None in data\n",
    "    conf_values_unique = np.unique([c for c in conf if c > 0])\n",
    "    print(\"Unique confidence values: \", conf_values_unique)\n",
    "\n",
    "    conf = np.array(conf)\n",
    "    # Extract low confidence trial indices\n",
    "    conf_low_indices = np.where((conf <= 2) & (conf > 0))[0]\n",
    "    #print('conf_low_indices: ', conf_low_indices)\n",
    "    print(\"Number of low confidence responses: \", len(conf_low_indices))\n",
    "    \n",
    "    # Extract high confidence trial indices\n",
    "    conf_high_indices = np.where(conf >= 3)[0]\n",
    "    print(\"Number of high confidence responses: \", len(conf_high_indices))\n",
    "    \n",
    "    print('Number of None ( = -1): ', len(np.where(conf == -1)[0]))\n",
    "    print('Number of no-resp ( = 0): ', len(np.where(conf == 0)[0]))\n",
    "    print('Total confidence questions: ', len(np.where(conf > -1)[0]))\n",
    "\n",
    "    # Get low confidence trials\n",
    "    low_conf_epochs = epochs[conf_low_indices]\n",
    "    for e in low_conf_epochs.event_id:\n",
    "        if 'real' in e:\n",
    "            print('ERROR: real events found in low conf!')\n",
    "            print(e)\n",
    "            \n",
    "        if 'nores' in e:\n",
    "            print('In low conf ' + str(e) + ' detected: ' + str(len(low_conf_epochs[e].get_data())))\n",
    "    \n",
    "    # Get high confidence trials\n",
    "    high_conf_epochs = epochs[conf_high_indices]\n",
    "    for e in high_conf_epochs.event_id:\n",
    "        if 'real' in e:\n",
    "            print('ERROR: real events found in high conf!')\n",
    "            print(e)\n",
    "            \n",
    "        if 'nores' in e:\n",
    "            print('In high conf ' + str(e) + ' detected: ' + str(len(high_conf_epochs[e].get_data())))\n",
    "    \n",
    "    return low_conf_epochs, high_conf_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData_conf_behavior(label, epochs, confLevelName):\n",
    "  \n",
    "    # Check if the given event label exist in the given data (low conf trials OR high conf trials)\n",
    "    if label in epochs.event_id: \n",
    "        new_epochs = epochs[label]\n",
    "        data = new_epochs.get_data()\n",
    "    else:\n",
    "        print('Warning: Event ( ' + label + ' ) not found in the ' + confLevelName + ' data! Returning empty list!')\n",
    "        data = []\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepareData_conf_pred(data_omission_living_lowConf_list, data_omission_living_highConf_list, data_omission_obj_lowConf_list, data_omission_obj_highConf_list):\n",
    "    \n",
    "    #Low Confidence\n",
    "    data_omission_living_lowConf = concatNonEmpty(data_omission_living_lowConf_list)\n",
    "    labels_omission_living_lowConf = np.zeros(len(data_omission_living_lowConf))\n",
    "    #print('living low conf: ', len(labels_omission_living_lowConf))\n",
    "\n",
    "    data_omission_obj_lowConf = concatNonEmpty(data_omission_obj_lowConf_list)\n",
    "    labels_omission_obj_lowConf = np.ones(len(data_omission_obj_lowConf))\n",
    "    #print('obj low conf: ', len(labels_omission_obj_lowConf))\n",
    "\n",
    "    #Combine\n",
    "    data_omission_lowConf = concatNonEmpty([data_omission_living_lowConf, data_omission_obj_lowConf])\n",
    "    labels_omission_lowConf = concatNonEmpty([labels_omission_living_lowConf, labels_omission_obj_lowConf])\n",
    "\n",
    "    #High Confidence\n",
    "\n",
    "    data_omission_living_highConf = concatNonEmpty(data_omission_living_highConf_list)\n",
    "    labels_omission_living_highConf = np.zeros(len(data_omission_living_highConf))\n",
    "    #print('living high conf: ', len(labels_omission_living_highConf))\n",
    "\n",
    "    data_omission_obj_highConf = concatNonEmpty(data_omission_obj_highConf_list)\n",
    "    labels_omission_obj_highConf = np.ones(len(data_omission_obj_highConf))\n",
    "    #print('obj high conf: ', len(labels_omission_obj_highConf))\n",
    "\n",
    "    #Combine\n",
    "    data_omission_highConf = concatNonEmpty([data_omission_living_highConf, data_omission_obj_highConf])\n",
    "    labels_omission_highConf = concatNonEmpty([labels_omission_living_highConf, labels_omission_obj_highConf])\n",
    "\n",
    "    return data_omission_lowConf, data_omission_highConf, labels_omission_lowConf, labels_omission_highConf  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData_pred_behavior_conf(living_data_list, obj_data_list ):\n",
    "    \n",
    "    #Concatenate living trials\n",
    "    data_living_all = concatNonEmpty(living_data_list)\n",
    "    \n",
    "    #Concatenate object trials\n",
    "    data_obj_all = concatNonEmpty(obj_data_list)\n",
    "\n",
    "    # Generate labels\n",
    "    labels_living_all = np.zeros(len(data_living_all))\n",
    "    labels_obj_all = np.ones(len(data_obj_all))\n",
    "    \n",
    "    # Concatenate living and object trials\n",
    "    data_all = concatNonEmpty([data_living_all, data_obj_all])\n",
    "    labels_all = concatNonEmpty([labels_living_all, labels_obj_all])\n",
    "    \n",
    "    return data_all, labels_all\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataByParticipant(s_id, task_name, fname, sensors, filep):\n",
    "    \n",
    "    #Check if data is already resampled!\n",
    "    fname_resampled = fname[:-4]+'_resampled.fif'\n",
    "        \n",
    "    if os.path.isfile(fname_resampled): \n",
    "        print('Already resampled data!')\n",
    "        epochs = loadData(s_id, sensors, fname_resampled, resampled=True)\n",
    "    else:\n",
    "        print('Data will be resampled!')\n",
    "        epochs = loadData(s_id, sensors, fname, resampled=False) \n",
    "        \n",
    "\n",
    "    #Real data and labels\n",
    "    data_real_living, labels_real_living = extractDataAndLabels(epochs, ['living_real_8', 'living_real_9', \n",
    "                                                                         'living_real_10'])\n",
    "    \n",
    "    data_real_object, labels_real_object = extractDataAndLabels(epochs, ['object_real_8', 'object_real_9',\n",
    "                                                                         'object_real_10'])\n",
    "    #print(len(data_real_living))\n",
    "    #living omission data and labels\n",
    "    data_omission_living_corr, labels_omission_living_corr = extractDataAndLabels(epochs, ['living_omission_8_corr',\n",
    "                                                                                           'living_omission_9_corr',\n",
    "                                                                                           'living_omission_10_corr'])\n",
    "    \n",
    "    data_omission_living_incorr, labels_omission_living_incorr = extractDataAndLabels(epochs,\n",
    "                                                                                      ['living_omission_8_incorr',\n",
    "                                                                                       'living_omission_9_incorr',\n",
    "                                                                                       'living_omission_10_incorr'])\n",
    "\n",
    "    #object omission data and labels\n",
    "    data_omission_object_corr, labels_omission_object_corr = extractDataAndLabels(epochs, ['object_omission_8_corr',\n",
    "                                                                                           'object_omission_9_corr',\n",
    "                                                                                           'object_omission_10_corr'])\n",
    "    \n",
    "    data_omission_object_incorr, labels_omission_object_incorr = extractDataAndLabels(epochs,\n",
    "                                                                                      ['object_omission_8_incorr',\n",
    "                                                                                       'object_omission_9_incorr',\n",
    "                                                                                        'object_omission_10_incorr'])\n",
    "\n",
    "    #Combine all data\n",
    "    # ------------------------- Real sounds -------------------------\n",
    "    # Concatenate all levels for REAL LIVING sounds\n",
    "    data_real_living_all = concatNonEmpty(data_real_living)\n",
    "    labels_real_living_all = concatNonEmpty(labels_real_living)\n",
    "    print('Shape of data real living: ', data_real_living_all.shape)\n",
    "    \n",
    "    # Concatenate all levels for REAL OBJECT sounds\n",
    "    data_real_obj_all = concatNonEmpty(data_real_object)\n",
    "    labels_real_object_all = concatNonEmpty(labels_real_object)\n",
    "    \n",
    "    # Concatenate real LIVING and real OBJECT\n",
    "    data_real_all = np.concatenate((data_real_living_all, data_real_obj_all))\n",
    "    labels_real_all = np.concatenate((labels_real_living_all, labels_real_object_all))\n",
    "\n",
    "    # ------------------------- Omissions -------------------------\n",
    "    # ----- CORRECT ------\n",
    "    #Concatenate all levels for omission LIVING and CORRECT\n",
    "    data_omission_living_all_corr = concatNonEmpty(data_omission_living_corr)\n",
    "    labels_omission_living_all_corr = concatNonEmpty(labels_omission_living_corr)\n",
    "    \n",
    "    #Concatenate all levels for omission OBJECT and CORRECT\n",
    "    data_omission_obj_all_corr = concatNonEmpty(data_omission_object_corr)\n",
    "    labels_omission_obj_all_corr = concatNonEmpty(labels_omission_object_corr)\n",
    "\n",
    "    #Concatenate omission LIVING&CORRECT and OBJECT&CORRECT\n",
    "    data_omission_all_corr = np.concatenate((data_omission_living_all_corr, data_omission_obj_all_corr))\n",
    "    labels_omission_all_corr = np.concatenate((labels_omission_living_all_corr, labels_omission_obj_all_corr))\n",
    "\n",
    "\n",
    "    # ----- INCORRECT ------\n",
    "    #Concatenate all levels for omission LIVING and INCORRECT\n",
    "    data_omission_living_all_incorr = concatNonEmpty(data_omission_living_incorr)\n",
    "    labels_omission_living_all_incorr = concatNonEmpty(labels_omission_living_incorr)\n",
    "\n",
    "    #Concatenate all levels for omission OBJECT and INCORRECT\n",
    "    data_omission_obj_all_incorr = concatNonEmpty(data_omission_object_incorr)\n",
    "    labels_omission_obj_all_incorr = concatNonEmpty(labels_omission_object_incorr)\n",
    "\n",
    "    #Concatenate omission LIVING&INCORRECT and OBJECT&INCORRECT\n",
    "    data_omission_all_incorr = np.concatenate((data_omission_living_all_incorr, data_omission_obj_all_incorr))\n",
    "    labels_omission_all_incorr = np.concatenate((labels_omission_living_all_incorr, labels_omission_obj_all_incorr))\n",
    "\n",
    "\n",
    "    # ------------------------- 80% -------------------------\n",
    "    # ------- Real sounds -----\n",
    "    data_real_8 = concatNonEmpty([data_real_living[0], data_real_object[0]])\n",
    "    labels_real_8 = concatNonEmpty([labels_real_living[0],labels_real_object[0]])\n",
    "\n",
    "    #------- Omissions -----\n",
    "    # ---- CORRECT ----\n",
    "    data_omission_8_corr = concatNonEmpty([data_omission_living_corr[0], data_omission_object_corr[0]])\n",
    "    labels_omission_8_corr = concatNonEmpty([labels_omission_living_corr[0], labels_omission_object_corr[0]])\n",
    "\n",
    "    # ---- INCORRECT ----\n",
    "    data_omission_8_incorr = concatNonEmpty([data_omission_living_incorr[0], data_omission_object_incorr[0]])\n",
    "    labels_omission_8_incorr = concatNonEmpty([labels_omission_living_incorr[0], labels_omission_object_incorr[0]])\n",
    "\n",
    "    # ------------------------- 90% -------------------------\n",
    "    # ------- Real sounds -----\n",
    "    data_real_9 = concatNonEmpty([data_real_living[1], data_real_object[1]])\n",
    "    labels_real_9 = concatNonEmpty([labels_real_living[1],labels_real_object[1]])\n",
    "\n",
    "    #------- Omissions -----\n",
    "    # ---- CORRECT ----\n",
    "    data_omission_9_corr = concatNonEmpty([data_omission_living_corr[1], data_omission_object_corr[1]])\n",
    "    labels_omission_9_corr = concatNonEmpty([labels_omission_living_corr[1], labels_omission_object_corr[1]])\n",
    "\n",
    "    # ---- INCORRECT ----\n",
    "    data_omission_9_incorr = concatNonEmpty([data_omission_living_incorr[1], data_omission_object_incorr[1]])\n",
    "    labels_omission_9_incorr = concatNonEmpty([labels_omission_living_incorr[1], labels_omission_object_incorr[1]])\n",
    "\n",
    "\n",
    "    # ------------------------- 100% -------------------------\n",
    "    # ------- Real sounds -----\n",
    "    data_real_10 = concatNonEmpty([data_real_living[2], data_real_object[2]])\n",
    "    labels_real_10 = concatNonEmpty([labels_real_living[2],labels_real_object[2]])\n",
    "\n",
    "    #------- Omissions -----\n",
    "    # ---- CORRECT ----\n",
    "    data_omission_10_corr = concatNonEmpty([data_omission_living_corr[2], data_omission_object_corr[2]])\n",
    "    labels_omission_10_corr = concatNonEmpty([labels_omission_living_corr[2], labels_omission_object_corr[2]])\n",
    "\n",
    "    # ---- INCORRECT ----\n",
    "    data_omission_10_incorr = concatNonEmpty([data_omission_living_incorr[2], data_omission_object_incorr[2]])\n",
    "    labels_omission_10_incorr = concatNonEmpty([labels_omission_living_incorr[2], labels_omission_object_incorr[2]])\n",
    "\n",
    "    \n",
    "    # Real sounds by predictability level and all of them together\n",
    "    data_real = [data_real_8, data_real_9, data_real_10, data_real_all]\n",
    "    labels_real = [labels_real_8, labels_real_9, labels_real_10, labels_real_all]\n",
    "    \n",
    "    # All omisssions\n",
    "    data_omissions, labels_omissions = [], []\n",
    "    \n",
    "    if task_name == 'all_predLevel':\n",
    "        # Combine data by predictability lecvel\n",
    "        data_omissions_8 = concatNonEmpty([data_omission_8_corr, data_omission_8_incorr])\n",
    "        labels_omissions_8 = concatNonEmpty([labels_omission_8_corr, labels_omission_8_incorr])\n",
    "\n",
    "        data_omissions_9 = concatNonEmpty([data_omission_9_corr, data_omission_9_incorr])\n",
    "        labels_omissions_9 = concatNonEmpty([labels_omission_9_corr, labels_omission_9_incorr])\n",
    "\n",
    "        data_omissions_10 = concatNonEmpty([data_omission_10_corr, data_omission_10_incorr])\n",
    "        labels_omissions_10 = concatNonEmpty([labels_omission_10_corr, labels_omission_10_incorr])\n",
    "\n",
    "        data_omissions_all = concatNonEmpty([data_omission_all_corr, data_omission_all_incorr])\n",
    "        labels_omissions_all = concatNonEmpty([labels_omission_all_corr, labels_omission_all_incorr])\n",
    "\n",
    "        data_omissions = [data_omissions_8, data_omissions_9, data_omissions_10, data_omissions_all]\n",
    "        labels_omissions = [labels_omissions_8, labels_omissions_9, labels_omissions_10, labels_omissions_all]\n",
    "        \n",
    "    elif task_name == 'all_incorrVScorr':\n",
    "        print('Number of correct trials: ', len(data_omission_all_corr))\n",
    "        print('Number of incorrect trials: ', len(data_omission_all_incorr))\n",
    "        data_omissions = [data_omission_all_corr, data_omission_all_incorr]\n",
    "        labels_omissions = [labels_omission_all_corr, labels_omission_all_incorr]\n",
    "        \n",
    "    elif 'conf' in task_name:\n",
    "        \n",
    "        confFile = filep + 'S' + s_id + '\\\\' + s_id + \"_confValues_AR.npy\"\n",
    "        \n",
    "        #Separate low confidence trials and high confidence trials\n",
    "        low_conf_epochs, high_conf_epochs = splitEpochs_byConfidence(confFile, epochs)\n",
    "        print('number of low conf epochs: ', len(low_conf_epochs))\n",
    "        print('number of high conf epochs: ', len(high_conf_epochs))\n",
    "        \n",
    "        #------------------ Low confidence ------------------\n",
    "        # --------- Living ---------\n",
    "        data_omission_living_8_corr_lowConf = prepareData_conf_behavior(\"living_omission_8_corr\", \n",
    "                                                                        low_conf_epochs, 'low')\n",
    "        \n",
    "        data_omission_living_8_incorr_lowConf = prepareData_conf_behavior(\"living_omission_8_incorr\", \n",
    "                                                                          low_conf_epochs, 'low')\n",
    "\n",
    "        data_omission_living_9_corr_lowConf = prepareData_conf_behavior(\"living_omission_9_corr\", \n",
    "                                                                        low_conf_epochs, 'low')    \n",
    "        \n",
    "        data_omission_living_9_incorr_lowConf = prepareData_conf_behavior(\"living_omission_9_incorr\", \n",
    "                                                                          low_conf_epochs, 'low')    \n",
    "\n",
    "        data_omission_living_10_corr_lowConf = prepareData_conf_behavior(\"living_omission_10_corr\", \n",
    "                                                                         low_conf_epochs, 'low')    \n",
    "        \n",
    "        data_omission_living_10_incorr_lowConf = prepareData_conf_behavior(\"living_omission_10_incorr\",\n",
    "                                                                           low_conf_epochs, 'low')    \n",
    "        \n",
    "        print('----------------')\n",
    "\n",
    "        # --------- Object ---------\n",
    "        data_omission_obj_8_corr_lowConf = prepareData_conf_behavior(\"object_omission_8_corr\",\n",
    "                                                                     low_conf_epochs, 'low')\n",
    "        \n",
    "        data_omission_obj_8_incorr_lowConf = prepareData_conf_behavior(\"object_omission_8_incorr\", \n",
    "                                                                       low_conf_epochs, 'low')\n",
    "\n",
    "        data_omission_obj_9_corr_lowConf = prepareData_conf_behavior(\"object_omission_9_corr\", \n",
    "                                                                     low_conf_epochs, 'low')\n",
    "        \n",
    "        data_omission_obj_9_incorr_lowConf = prepareData_conf_behavior(\"object_omission_9_incorr\", \n",
    "                                                                       low_conf_epochs, 'low')\n",
    "\n",
    "        data_omission_obj_10_corr_lowConf = prepareData_conf_behavior(\"object_omission_10_corr\",\n",
    "                                                                      low_conf_epochs, 'low')\n",
    "        data_omission_obj_10_incorr_lowConf = prepareData_conf_behavior(\"object_omission_10_incorr\",\n",
    "                                                                        low_conf_epochs, 'low')\n",
    "        print('----------------')\n",
    "\n",
    "\n",
    "        #------------------ High confidence ------------------\n",
    "        # --------- Living ---------\n",
    "        data_omission_living_8_corr_highConf = prepareData_conf_behavior(\"living_omission_8_corr\",\n",
    "                                                                         high_conf_epochs, 'high')\n",
    "        \n",
    "        data_omission_living_8_incorr_highConf = prepareData_conf_behavior(\"living_omission_8_incorr\", \n",
    "                                                                           high_conf_epochs, 'high')\n",
    "\n",
    "        data_omission_living_9_corr_highConf = prepareData_conf_behavior(\"living_omission_9_corr\",\n",
    "                                                                         high_conf_epochs, 'high')  \n",
    "        \n",
    "        data_omission_living_9_incorr_highConf = prepareData_conf_behavior(\"living_omission_9_incorr\", \n",
    "                                                                           high_conf_epochs, 'high')    \n",
    "\n",
    "        data_omission_living_10_corr_highConf = prepareData_conf_behavior(\"living_omission_10_corr\",\n",
    "                                                                          high_conf_epochs, 'high')    \n",
    "        \n",
    "        data_omission_living_10_incorr_highConf = prepareData_conf_behavior(\"living_omission_10_incorr\",\n",
    "                                                                            high_conf_epochs, 'high')    \n",
    "\n",
    "        print('----------------')\n",
    "        \n",
    "        # --------- Object ---------\n",
    "        data_omission_obj_8_corr_highConf = prepareData_conf_behavior(\"object_omission_8_corr\",\n",
    "                                                                      high_conf_epochs, 'high')\n",
    "        \n",
    "        data_omission_obj_8_incorr_highConf = prepareData_conf_behavior(\"object_omission_8_incorr\",\n",
    "                                                                        high_conf_epochs, 'high')\n",
    "\n",
    "        data_omission_obj_9_corr_highConf = prepareData_conf_behavior(\"object_omission_9_corr\",\n",
    "                                                                      high_conf_epochs, 'high')\n",
    "        \n",
    "        data_omission_obj_9_incorr_highConf = prepareData_conf_behavior(\"object_omission_9_incorr\",\n",
    "                                                                        high_conf_epochs, 'high')\n",
    "\n",
    "        data_omission_obj_10_corr_highConf = prepareData_conf_behavior(\"object_omission_10_corr\",\n",
    "                                                                       high_conf_epochs, 'high')\n",
    "        \n",
    "        data_omission_obj_10_incorr_highConf = prepareData_conf_behavior(\"object_omission_10_incorr\",\n",
    "                                                                         high_conf_epochs, 'high')\n",
    "        \n",
    "        \n",
    "        \n",
    "        if task_name == 'behavior_conf_pred': # Split data based on all 3 experimental conditions\n",
    "            print('!! behavior_conf_pred !!')\n",
    "            # ------- 80% & CORRECT & LOW confidence -------\n",
    "            data_omission_8_corr_lowConf, labels_omission_8_corr_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_8_corr_lowConf], [data_omission_obj_8_corr_lowConf])    \n",
    "            \n",
    "            # ------- 90% & CORRECT & LOW confidence -------\n",
    "            data_omission_9_corr_lowConf, labels_omission_9_corr_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_9_corr_lowConf], [data_omission_obj_9_corr_lowConf])  \n",
    "            \n",
    "            # ------- 100% & CORRECT & LOW confidence -------\n",
    "            data_omission_10_corr_lowConf, labels_omission_10_corr_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_10_corr_lowConf], [data_omission_obj_10_corr_lowConf]) \n",
    "            \n",
    "            # =====================================\n",
    "            \n",
    "            # ------- 80% & INCORRECT & LOW confidence -------\n",
    "            data_omission_8_incorr_lowConf, labels_omission_8_incorr_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_8_incorr_lowConf], [data_omission_obj_8_incorr_lowConf])    \n",
    "            \n",
    "            # ------- 90% & INCORRECT & LOW confidence -------\n",
    "            data_omission_9_incorr_lowConf, labels_omission_9_incorr_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_9_incorr_lowConf], [data_omission_obj_9_incorr_lowConf])  \n",
    "            \n",
    "            # ------- 100% & INCORRECT & LOW confidence -------\n",
    "            data_omission_10_incorr_lowConf, labels_omission_10_incorr_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_10_incorr_lowConf], [data_omission_obj_10_incorr_lowConf]) \n",
    "            \n",
    "            # =====================================\n",
    "            \n",
    "            # ------- 80% & CORRECT & HIGH confidence -------\n",
    "            data_omission_8_corr_highConf, labels_omission_8_corr_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_8_corr_highConf], [data_omission_obj_8_corr_highConf])    \n",
    "            \n",
    "            # ------- 90% & CORRECT & HIGH confidence -------\n",
    "            data_omission_9_corr_highConf, labels_omission_9_corr_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_9_corr_highConf], [data_omission_obj_9_corr_highConf])  \n",
    "            \n",
    "            # ------- 100% & CORRECT & HIGH confidence -------\n",
    "            data_omission_10_corr_highConf, labels_omission_10_corr_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_10_corr_highConf], [data_omission_obj_10_corr_highConf]) \n",
    "            \n",
    "            # =====================================\n",
    "            \n",
    "            # ------- 80% & INCORRECT & HIGH confidence -------\n",
    "            data_omission_8_incorr_highConf, labels_omission_8_incorr_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_8_incorr_highConf], [data_omission_obj_8_incorr_highConf])    \n",
    "            \n",
    "            # ------- 90% & INCORRECT & HIGH confidence -------\n",
    "            data_omission_9_incorr_highConf, labels_omission_9_incorr_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_9_incorr_highConf], [data_omission_obj_9_incorr_highConf])  \n",
    "            \n",
    "            # ------- 100% & INCORRECT & HIGH confidence -------\n",
    "            data_omission_10_incorr_highConf, labels_omission_10_incorr_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_10_incorr_highConf], [data_omission_obj_10_incorr_highConf]) \n",
    "            \n",
    "            # Data to return: \n",
    "            # 80 & C & L, 90 & C & L, 100 & C & L\n",
    "            # 80 & I & L, 90 & I & L, 100 & I & L\n",
    "            # 80 & C & H, 90 & C & L, 100 & C & H\n",
    "            # 80 & I & H, 90 & I & H, 100 & I & H\n",
    "            data_omissions = [data_omission_8_corr_lowConf, data_omission_9_corr_lowConf,\n",
    "                              data_omission_10_corr_lowConf,\n",
    "                             data_omission_8_incorr_lowConf, data_omission_9_incorr_lowConf,\n",
    "                              data_omission_10_incorr_lowConf,\n",
    "                             data_omission_8_corr_highConf, data_omission_9_corr_highConf,\n",
    "                              data_omission_10_corr_highConf,\n",
    "                             data_omission_8_incorr_highConf, data_omission_9_incorr_highConf,\n",
    "                              data_omission_10_incorr_highConf]\n",
    "            \n",
    "            \n",
    "            labels_omissions = [labels_omission_8_corr_lowConf, labels_omission_9_corr_lowConf,\n",
    "                                labels_omission_10_corr_lowConf,\n",
    "                               labels_omission_8_incorr_lowConf, labels_omission_9_incorr_lowConf,\n",
    "                                labels_omission_10_incorr_lowConf,\n",
    "                               labels_omission_8_corr_highConf, labels_omission_9_corr_highConf,\n",
    "                                labels_omission_10_corr_highConf,\n",
    "                               labels_omission_8_incorr_highConf, labels_omission_9_incorr_highConf,\n",
    "                                labels_omission_10_incorr_highConf]\n",
    "            \n",
    "            \n",
    "        elif task_name == 'conf_pred': # Split data based on predictability and confidence\n",
    "            print('Data is getting prepared for the task: ', task_name)\n",
    "            # 80% & LOW confidence\n",
    "            data_omission_8_lowConf, labels_omission_8_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_8_corr_lowConf, data_omission_living_8_incorr_lowConf], \n",
    "                [data_omission_obj_8_corr_lowConf, data_omission_obj_8_incorr_lowConf])    \n",
    "            \n",
    "            # ------- 90% & CORRECT & LOW confidence -------\n",
    "            data_omission_9_lowConf, labels_omission_9_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_9_corr_lowConf, data_omission_living_9_incorr_lowConf],\n",
    "                [data_omission_obj_9_corr_lowConf, data_omission_obj_9_incorr_lowConf])  \n",
    "            \n",
    "            # ------- 100% & CORRECT & LOW confidence -------\n",
    "            data_omission_10_lowConf, labels_omission_10_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_10_corr_lowConf, data_omission_living_10_incorr_lowConf],\n",
    "                [data_omission_obj_10_corr_lowConf, data_omission_obj_10_incorr_lowConf]) \n",
    "            \n",
    "\n",
    "            # ------- 80% & HIGH confidence -------\n",
    "            data_omission_8_highConf, labels_omission_8_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_8_corr_highConf, data_omission_living_8_incorr_highConf],\n",
    "                [data_omission_obj_8_corr_highConf, data_omission_obj_8_incorr_highConf])    \n",
    "            \n",
    "            # ------- 90% & CORRECT & HIGH confidence -------\n",
    "            data_omission_9_highConf, labels_omission_9_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_9_corr_highConf, data_omission_living_9_incorr_highConf],\n",
    "                [data_omission_obj_9_corr_highConf, data_omission_obj_9_incorr_highConf])  \n",
    "            \n",
    "            # ------- 100% & CORRECT & HIGH confidence -------\n",
    "            data_omission_10_highConf, labels_omission_10_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_10_corr_highConf, data_omission_living_10_incorr_highConf],\n",
    "                [data_omission_obj_10_corr_highConf, data_omission_obj_10_incorr_highConf]) \n",
    "            \n",
    "            \n",
    "            # Data to return: \n",
    "            # 80 & L, 90 & L, 100 & L,\n",
    "            # 80 & H, 90 & H, 100 & H\n",
    "            data_omissions = [data_omission_8_lowConf, data_omission_9_lowConf, data_omission_10_lowConf,\n",
    "                             data_omission_8_highConf, data_omission_9_highConf, data_omission_10_highConf]\n",
    "            \n",
    "            \n",
    "            labels_omissions = [labels_omission_8_lowConf, labels_omission_9_lowConf, labels_omission_10_lowConf,\n",
    "                               labels_omission_8_highConf, labels_omission_9_highConf, labels_omission_10_highConf]\n",
    "            \n",
    "            \n",
    "        else: # Use confidence only OR behavior and confidence to split data (do not split by predictability level)\n",
    "            \n",
    "            #--------------------------- Omissions ---------------------------\n",
    "\n",
    "            # --------------- Correct -------------\n",
    "            # ---- Low Confidence ----    \n",
    "            data_omission_all_corr_lowConf, labels_omission_all_corr_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_8_corr_lowConf, data_omission_living_9_corr_lowConf,\n",
    "                 data_omission_living_10_corr_lowConf],\n",
    "                [data_omission_obj_8_corr_lowConf, data_omission_obj_9_corr_lowConf,\n",
    "                 data_omission_obj_10_corr_lowConf])\n",
    "            \n",
    "            # ---- High Confidence ----\n",
    "            data_omission_all_corr_highConf, labels_omission_all_corr_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_8_corr_highConf, data_omission_living_9_corr_highConf,\n",
    "                 data_omission_living_10_corr_highConf],\n",
    "                [data_omission_obj_8_corr_highConf, data_omission_obj_9_corr_highConf,\n",
    "                 data_omission_obj_10_corr_highConf])\n",
    "\n",
    "            # --------------- Incorrect -------------\n",
    "            # ---- Low Confidence ----\n",
    "            data_omission_all_incorr_lowConf, labels_omission_all_incorr_lowConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_8_incorr_lowConf, data_omission_living_9_incorr_lowConf, \n",
    "                 data_omission_living_10_incorr_lowConf],\n",
    "                [data_omission_obj_8_incorr_lowConf, data_omission_obj_9_incorr_lowConf, \n",
    "                 data_omission_obj_10_incorr_lowConf])   \n",
    "    \n",
    "            # ---- High Confidence ----\n",
    "            data_omission_all_incorr_highConf, labels_omission_all_incorr_highConf = prepareData_pred_behavior_conf(\n",
    "                [data_omission_living_8_incorr_highConf, data_omission_living_9_incorr_highConf,\n",
    "                 data_omission_living_10_incorr_highConf],\n",
    "                [data_omission_obj_8_incorr_highConf, data_omission_obj_9_incorr_highConf,\n",
    "                 data_omission_obj_10_incorr_highConf])\n",
    "\n",
    "            if task_name == \"behavior_conf\": # C & L --- C & H --- I & L --- I & H\n",
    "                print('confidence and behaviour!')\n",
    "                data_omissions = [data_omission_all_corr_lowConf, data_omission_all_corr_highConf, \n",
    "                                  data_omission_all_incorr_lowConf, data_omission_all_incorr_highConf]\n",
    "\n",
    "                labels_omissions = [labels_omission_all_corr_lowConf, labels_omission_all_corr_highConf,\n",
    "                                   labels_omission_all_incorr_lowConf, labels_omission_all_incorr_highConf]\n",
    "\n",
    "            elif task_name == 'all_conf': # splitting just based on CONFIDENCE\n",
    "                print('Only confidence!')\n",
    "                \n",
    "                # ---- lOW CONFIDENCE ----\n",
    "                data_omission_lowConf_all = concatNonEmpty([data_omission_all_corr_lowConf,\n",
    "                                                            data_omission_all_incorr_lowConf])\n",
    "                \n",
    "                labels_omission_lowConf_all = concatNonEmpty([labels_omission_all_corr_lowConf,\n",
    "                                                              labels_omission_all_incorr_lowConf])\n",
    "\n",
    "                # ---- HIGH CONFIDENCE ----\n",
    "                data_omission_highConf_all = concatNonEmpty([data_omission_all_corr_highConf,\n",
    "                                                             data_omission_all_incorr_highConf]) \n",
    "                \n",
    "                labels_omission_highConf_all = concatNonEmpty([labels_omission_all_corr_highConf,\n",
    "                                                               labels_omission_all_incorr_highConf])                                                                                                         \n",
    "\n",
    "                data_omissions = [data_omission_lowConf_all, data_omission_highConf_all]\n",
    "                labels_omissions = [labels_omission_lowConf_all, labels_omission_highConf_all]\n",
    "\n",
    "\n",
    "    \n",
    "    return epochs, data_real, labels_real, data_omissions, labels_omissions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MVPA functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParams(filename):\n",
    "    params, words = [], []\n",
    "    \n",
    "    with open(filename,'r') as file: \n",
    "        for line in file:         \n",
    "            words.append(line.split())\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        params.append(words[i][-1])\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTest_MVPA(data_real, labels_real, test_data, test_labels, outputfilename, bestParametersFile,\n",
    "                      tlim, modelsFile, nFolds=5, bestParamsFound=False):\n",
    "        \n",
    "    train_data_real, test_data_real, train_labels_real, test_labels_real = train_test_split(data_real, labels_real, \n",
    "                                                                                            test_size=0.25,\n",
    "                                                                                            random_state=42,\n",
    "                                                                                            stratify=labels_real)  \n",
    "    repeats = nFolds\n",
    "    rkf = RepeatedKFold(n_splits=nFolds, n_repeats=repeats, random_state=42)\n",
    "    \n",
    "    '''\n",
    "    if bestParamsFound == False:\n",
    "        # 2. make optimization pipeline:\n",
    "        \n",
    "        parameters = {'penalty': ['l1', 'l2']}\n",
    "        clf_opt = make_pipeline(Vectorizer(), StandardScaler(), GridSearchCV(LogisticRegression(),parameters,cv=rkf))\n",
    "\n",
    "        # 3. Use CV data to fit and optimize our classifier:\n",
    "        clf_opt.fit(train_data_real, train_labels_real)\n",
    "        # 4. retrieve optimal parameters:\n",
    "        tmp = clf_opt.steps[-1][1]       \n",
    "        best_c = tmp.best_params_['C']\n",
    "        best_penalty = tmp.best_params_['penalty']\n",
    "        # 5. Use the optimized classifier on the test dataset (w/o time):\n",
    "        score = clf_opt.score(test_data_real, test_labels_real)\n",
    "\n",
    "        print(score)\n",
    "        print('best penalty: ', best_penalty)\n",
    "        print('best C: ', best_c)\n",
    "        #save the best params for later use\n",
    "        file = open(bestParametersFile,\"w\") \n",
    "        file.writelines('best C: ' + str(best_c))\n",
    "        file.writelines('\\nbest penalty: ' + str(best_penalty))\n",
    "        file.close()\n",
    "    else:\n",
    "        [best_penalty] = getBestParams(bestParametersFile)\n",
    "    '''\n",
    "    \n",
    "    clf_tp = []\n",
    "    CV_score = np.zeros((repeats*nFolds, tlim))\n",
    "    Test_score_real = np.zeros((tlim))\n",
    "    Test_score_omissions = [np.zeros((tlim)) for i in range(len(test_data))]\n",
    "    clf_list = []\n",
    "    \n",
    "    for tp in np.arange(tlim):\n",
    "        #print(tp)\n",
    "\n",
    "        d2t_cv = train_data_real[:,:,tp] # data to test\n",
    "        d2t_test = test_data_real[:,:,tp] # data to test - real\n",
    "        \n",
    "        print('Penalty: l1')\n",
    "        clf = make_pipeline(StandardScaler(), LogisticRegression( solver='liblinear', penalty='l1')) #best_penalty\n",
    "        # get CV score:\n",
    "        CV_score[:,tp] = cross_val_score(clf, d2t_cv, train_labels_real, cv=rkf, scoring='roc_auc')        \n",
    "\n",
    "        # fit the model using all CV data:\n",
    "        clf.fit(d2t_cv, train_labels_real)\n",
    "        clf_list.append(clf)\n",
    "        # generalize performance on test data:\n",
    "        labels_test_estim= clf.predict(d2t_test)\n",
    "        \n",
    "        Test_score_real[tp] = roc_auc_score(test_labels_real,labels_test_estim)\n",
    "        \n",
    "        for i in range(len(test_data)):\n",
    "            if len(test_data[i]) > 0:\n",
    "                d2t_test_omissions = test_data[i][:,:,tp] # data to test - omissions_corr lowConf\n",
    "                labels_test_estim_omissions = clf.predict(d2t_test_omissions)\n",
    "                try:\n",
    "                    Test_score_omissions[i][tp] = roc_auc_score(test_labels[i], labels_test_estim_omissions)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            else:\n",
    "                Test_score_omissions[i][tp] = 0\n",
    "\n",
    "    results = [Test_score_real]\n",
    "    for i in range(len(test_data)):\n",
    "        results.append(Test_score_omissions[i])\n",
    "    results.append(CV_score)\n",
    "    np.save(outputfilename, results)\n",
    "    \n",
    "    '''  \n",
    "    with open(modelsFile, \"wb\") as f:\n",
    "        for model in clf_list:\n",
    "            pickle.dump(model, f)\n",
    "    \n",
    "    ''' \n",
    "    return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_MVPA(results, times, tlim, plotname, fullTrial=True, isBehavior=True):\n",
    "    \n",
    "    Test_score_real = results[0]\n",
    "    CV_score = results[-1]\n",
    "    if len(results) == 3:\n",
    "        Test_score_omissions = results[1]\n",
    "    elif len(results) == 4:\n",
    "        Test_score_omissions = [results[1], results[2]]\n",
    "    elif len(results) == 5:\n",
    "        Test_score_omissions = [results[1], results[2], results[3]]\n",
    "    #[Test_score_real, Test_score_omissions, CV_score] = results\n",
    "    if fullTrial == False:\n",
    "        end_of_omission = np.where(times == 0.3)[0][0]\n",
    "        times_omi = times[:end_of_omission+1]\n",
    "    else:\n",
    "        times_omi = times\n",
    "        end_of_omission = len(times)-1\n",
    "    \n",
    "    fig = plt.figure(num=None, figsize=(8, 2), dpi=150)\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = plt.plot(times_omi, Test_score_real[:end_of_omission+1],label = 'Test Real')\n",
    "    \n",
    "    if len(results) == 4:\n",
    "        if isBehavior == True:\n",
    "            labels = ['Test Omissions_correct', 'Test Omissions_incorrect']\n",
    "        else:\n",
    "            labels = ['Test Omissions_lowConf', 'Test Omissions_highConf']\n",
    "        \n",
    "\n",
    "        ax = plt.plot(times_omi, Test_score_omissions[0][:end_of_omission+1],label = labels[0])\n",
    "        ax = plt.plot(times_omi, Test_score_omissions[1][:end_of_omission+1],label = labels[1])\n",
    "    \n",
    "    elif len(results) == 5:\n",
    "        labels = ['Test Omissions - 80%', 'Test Omissions - 90%', 'Test Omissions - 100%']\n",
    "        for i in range(len(Test_score_omissions)):\n",
    "            ax = plt.plot(times_omi, Test_score_omissions[i][:end_of_omission+1],label = labels[i])\n",
    "    \n",
    "    else:\n",
    "        ax = plt.plot(times_omi, Test_score_omissions[:tlim],label = 'Test Omissions')\n",
    "        \n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.3))\n",
    "\n",
    "    plt.title('Test set')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = plt.plot(times, np.nanmean(CV_score, axis = 0)[:tlim],label = 'CV Real')\n",
    "    plt.title('Cross-validation set')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.3))\n",
    "\n",
    "    fig1 = plt.gcf()\n",
    "    fig1.savefig(plotname, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_MVPA_Group(results, labels, plotname):\n",
    "    print(len(results))\n",
    "    nrow = int(len(results)/2)-1\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), dpi=150)\n",
    "    \n",
    "    print(axs.shape)\n",
    "    #print(len(axs[0]))\n",
    "    if nrow > 1:\n",
    "        for i in range(nrow):\n",
    "\n",
    "            if i == 0:\n",
    "                axs[i, 0].plot(epochs.times[:tlim], np.nanmean(results[0], axis = 0)[:tlim],label = labels[0])\n",
    "                print(results[i][:tlim])\n",
    "            else:\n",
    "                axs[i, 0].plot(epochs.times[:tlim], results[i][:tlim],label = labels[i])\n",
    "                axs[i, 1].plot(epochs.times[:tlim], results[i*loop_size+2][:tlim],label = labels[i*loop_size+2])\n",
    "                axs[i, 1].plot(epochs.times[:tlim], results[i*loop_size+3][:tlim],label = labels[i*loop_size+3])\n",
    "    \n",
    "    elif nrow == 1:\n",
    "        axs[0].plot(epochs.times[:tlim], np.nanmean(results[0], axis = 0)[:tlim],label = labels[0])\n",
    "        axs[1].plot(epochs.times[:tlim], results[1][:tlim],label = labels[1])\n",
    "        axs[1].plot(epochs.times[:tlim], results[2][:tlim],label = labels[2])\n",
    "        axs[1].plot(epochs.times[:tlim], results[3],label = labels[3])\n",
    "       \n",
    "    \n",
    "    for i in range(len(axs.flat)):\n",
    "            if i == 0:\n",
    "                axs.flat[i].set_title('Cross-validation set')\n",
    "            else:\n",
    "                axs.flat[i].set_title('Test set')\n",
    "            axs.flat[i].set(xlabel='Time (s)', ylabel='Accuracy')\n",
    "            axs.flat[i].legend(loc='upper center', bbox_to_anchor=(0.1, -0.3))\n",
    "  \n",
    "    \n",
    "    #plt.xlabel('Time (s)')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig1 = plt.gcf()\n",
    "    fig1.savefig(plotname, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
