{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from functions_InverseSolutions import applyBeamformer, showResult, prepareInverseSolution_group, computeStatistic\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import mne\n",
    "from mayavi import mlab\n",
    "\n",
    "#import cmasher as cmr\n",
    "\n",
    "mlab.init_notebook('png')\n",
    "mne.viz.set_3d_backend('mayavi')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sensors = 'mag'\n",
    "tmin, tmax = -0.1, 0.6\n",
    "\n",
    "mainFolder = \"..\\Data\\\\\"\n",
    "print('main folder folder: ', mainFolder)\n",
    "\n",
    "meg_MainFolder = mainFolder + \"MEG_Data\\Data=\"\n",
    "print('meg main folder folder: ', meg_MainFolder)\n",
    "\n",
    "dataFolder = meg_MainFolder + str(tmin) + '_' + str(tmax) + '\\\\'\n",
    "print('Data folder: ', dataFolder)\n",
    "\n",
    "source_MainFolder = \"..\\SourceLocalization\\SourceEstimates\\Data=\"\n",
    "sourceFolder = source_MainFolder + str(tmin) + '_' + str(tmax) + '\\\\'\n",
    "print('Source folder: ', sourceFolder)\n",
    "\n",
    "subjects_dir = '..\\SourceLocalization\\subjects\\\\'\n",
    "print('Subjects directory: ', subjects_dir)\n",
    "\n",
    "forwardModelsFolder = '..\\SourceLocalization\\ForwardModels\\\\'\n",
    "print('Forward models folder: ', forwardModelsFolder)\n",
    "\n",
    "spatialFiltersFolder = '..\\SourceLocalization\\SpatialFilters\\\\Data='\n",
    "spatialFiltersFolder = spatialFiltersFolder + str(tmin) + '_' + str(tmax) + '\\\\'\n",
    "print('Spatial filters folder: ', spatialFiltersFolder)\n",
    "\n",
    "statResultsFolder  = '..\\SourceLocalization\\Results\\\\Data='\n",
    "statResultsFolder = statResultsFolder + str(tmin) + '_' + str(tmax) + '\\\\'\n",
    "print('Statisctics results folder: ', statResultsFolder)\n",
    "\n",
    "classifiers_MainFolder = \"..\\Classifiers\\Data=\"    \n",
    "clsfFolder = classifiers_MainFolder + str(tmin) + '_' + str(tmax) + '\\\\'\n",
    "print('Classifiers folder: ', clsfFolder)\n",
    "\n",
    "# Pick the classifiers based on the their training window\n",
    "peak_indices = [20, 50]\n",
    "print('Peak indices: ', peak_indices)\n",
    "    \n",
    "# Task name for the classifiers\n",
    "task_name = 'all_predLevel'\n",
    "print('Task name: ', task_name)\n",
    "\n",
    "ids_filename = 'Participant_ids.txt'\n",
    "participants_filename = 'Participants.txt'\n",
    "\n",
    "# All subjects\n",
    "s_id_list_all = np.loadtxt(mainFolder+ids_filename, dtype=str)\n",
    "s_id_list_all = s_id_list_all.tolist()\n",
    "\n",
    "participant_names = np.loadtxt(mainFolder+participants_filename, dtype=str)\n",
    "participant_names = participant_names.tolist()\n",
    "\n",
    "print('Number of subjects: ', len(participant_names))\n",
    "\n",
    "if os.path.exists(subjects_dir + '\\\\' + participant_names[0] + '\\surf\\\\'):  \n",
    "    print('exists!')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Read fsaverage\n",
    "\n",
    "# Read fsaverage\n",
    "src_ave = mne.read_source_spaces(subjects_dir + 'fsaverage\\\\bem\\\\fsaverage-ico-5-src.fif')\n",
    "fsave_vertices = [s['vertno'] for s in src_ave]\n",
    "\n",
    "#### Choose the conditions for contrasting\n",
    "\n",
    "conditions_8 = ['living_omission_8_nores', 'living_omission_8_corr', 'living_omission_8_incorr',\n",
    "                 'object_omission_8_nores', 'object_omission_8_corr', 'object_omission_8_incorr']\n",
    "\n",
    "conditions_10 = ['living_omission_10_nores', 'living_omission_10_corr', 'living_omission_10_incorr',\n",
    "                 'object_omission_10_nores', 'object_omission_10_corr', 'object_omission_10_incorr']\n",
    "condition_names =  [\"omi\"]\n",
    "\n",
    "n_subjects = len(s_id_list_all)\n",
    "print('number of subjects: ', n_subjects)\n",
    "\n",
    "print('conditions 80%: \\n', conditions_8)\n",
    "print('conditions 100%: \\n', conditions_10)\n",
    "\n",
    "### Define time limits for inverse solutions\n",
    "\n",
    "tminData, tmaxData = 0.1, 0.4  #0.1, 0.4 #-0.04, 0\n",
    "print('tmin for data: ', tminData)\n",
    "print('tmax for data: ', tmaxData)\n",
    "tminNoiseCov, tmaxNoiseCov = -0.1, -0.05\n",
    "print('tmin for noise covariance: ', tminNoiseCov)\n",
    "print('tmax for noise covariance: ', tmaxNoiseCov)\n",
    "tminEpoch = -0.1\n",
    "print('tmin for generated epochs: ', tminEpoch)\n",
    "smoothAmount = 70\n",
    "print('Smoothing amount: ', smoothAmount)\n",
    "inv_sol_method = 'beamformer'\n",
    "print('Inverse solution method: ', inv_sol_method)\n",
    "tstep=0.01\n",
    "\n",
    "### Use beamformer for computing source estimates\n",
    "\n",
    "print('======= Applying Beamformer ========')\n",
    "# 80%\n",
    "# time range of interest [0.1, 0.4]\n",
    "stc_omi_8_filename = 'stc_fsave_omi_8_onActivationMaps_'+inv_sol_method+'_'+str(tminData)+'_'+str(tmaxData)+'_sm='+str(smoothAmount)+'.npy'\n",
    "if os.path.exists(statResultsFolder + stc_omi_8_filename) != True:\n",
    "\n",
    "    stc_fsave_omi_8, n_times, tstep = applyBeamformer(conditions_8, s_id_list_all, n_subjects, participant_names, tminData,\n",
    "                                                      tmaxData, tminNoiseCov, tmaxNoiseCov, tminEpoch, smoothAmount,\n",
    "                                                      task_name, clsfFolder, peak_indices, src_ave, spatialFiltersFolder,\n",
    "                                                      subjects_dir, dataFolder, sensors, forwardModelsFolder)\n",
    "\n",
    "    print('stc omi is saved in ', stc_omi_8_filename)\n",
    "    np.save(statResultsFolder + stc_omi_8_filename, stc_fsave_omi_8)\n",
    "\n",
    "else: # If you have the source estimates values saved already, load them\n",
    "\n",
    "    # time range of interest [0.1, 0.4]\n",
    "    tminData_cls_tmp, tmaxData_cls_tmp = 0.1, 0.4\n",
    "    stc_omi_8_filename = 'stc_fsave_omi_8_onActivationMaps_'+inv_sol_method+'_'+str(tminData_cls_tmp)+'_'+str(tmaxData_cls_tmp)+'_sm='+str(smoothAmount)+'.npy'\n",
    "    print(statResultsFolder+stc_omi_8_filename)\n",
    "    stc_fsave_omi_8_clfRange = np.load(statResultsFolder+stc_omi_8_filename)\n",
    "    print('shape of omi 80% source estimates: ', stc_fsave_omi_8_clfRange.shape)\n",
    "    print(np.where(stc_fsave_omi_8_clfRange == 0))\n",
    "\n",
    "    ## Baseline [-0.04, 0]\n",
    "    tminData_baseline_tmp, tmaxData_baseline_tmp = -0.04, 0\n",
    "    stc_omi_8_filename_baseline = 'stc_fsave_omi_8_onActivationMaps_'+inv_sol_method+'_'+str(tminData_baseline_tmp)+'_'+str(tmaxData_baseline_tmp)+'_sm='+str(smoothAmount)+'.npy'\n",
    "    print(stc_omi_8_filename_baseline)\n",
    "    stc_fsave_omi_8_baseline = np.load(statResultsFolder+stc_omi_8_filename_baseline)\n",
    "    print('shape of omi 80% baseline source estimates: ', stc_fsave_omi_8_baseline.shape)\n",
    "    print(np.where(stc_fsave_omi_8_baseline == 0))\n",
    "\n",
    "\n",
    "\n",
    "#100%\n",
    "stc_omi_10_filename = 'stc_fsave_omi_10_onActivationMaps_'+inv_sol_method+'_'+str(tminData)+'_'+str(tmaxData)+'_sm='+str(smoothAmount)+'.npy'\n",
    "if os.path.exists(statResultsFolder + stc_omi_10_filename) != True:\n",
    "    stc_fsave_omi_10, n_times, tstep = applyBeamformer(conditions_10, s_id_list_all, n_subjects, participant_names, tminData,\n",
    "                                                       tmaxData, tminNoiseCov, tmaxNoiseCov, tminEpoch, smoothAmount,\n",
    "                                                       task_name, clsfFolder, peak_indices, src_ave, spatialFiltersFolder,\n",
    "                                                       subjects_dir, dataFolder, sensors, forwardModelsFolder)\n",
    "\n",
    "    print('stc omi is saved in ', stc_omi_10_filename)\n",
    "    np.save(statResultsFolder + stc_omi_10_filename, stc_fsave_omi_10)\n",
    "\n",
    "\n",
    "else:\n",
    "    # time range of interest [0.1, 0.4]\n",
    "\n",
    "    tminData_cls_tmp, tmaxData_cls_tmp = 0.1, 0.4\n",
    "    stc_omi_10_filename = 'stc_fsave_omi_10_onActivationMaps_'+inv_sol_method+'_'+str(tminData_cls_tmp)+'_'+str(tmaxData_cls_tmp)+'_sm='+str(smoothAmount)+'.npy'\n",
    "    print(statResultsFolder+stc_omi_10_filename)\n",
    "    stc_fsave_omi_10_clfRange = np.load(statResultsFolder+stc_omi_10_filename)\n",
    "    print('shape of omi 100% source estimates: ', stc_fsave_omi_10_clfRange.shape)\n",
    "    print(np.where(stc_fsave_omi_10_clfRange == 0))\n",
    "\n",
    "    ## Baseline [-0.04, 0]\n",
    "    tminData_baseline_tmp, tmaxData_baseline_tmp = -0.04, 0\n",
    "    # 100%\n",
    "    stc_omi_10_filename_baseline = 'stc_fsave_omi_10_onActivationMaps_'+inv_sol_method+'_'+str(tminData_baseline_tmp)+'_'+str(tmaxData_baseline_tmp)+'_sm='+str(smoothAmount)+'.npy'\n",
    "    print(stc_omi_10_filename_baseline)\n",
    "    stc_fsave_omi_10_baseline = np.load(statResultsFolder+stc_omi_10_filename_baseline)\n",
    "    print('shape of omi 100% baseline source estimates: ', stc_fsave_omi_10_baseline.shape)\n",
    "    print(np.where(stc_fsave_omi_10_baseline == 0))\n",
    "\n",
    "### Check data before doing anything!!\n",
    "\n",
    "#print(stc_fsave_omi_8_baseline)\n",
    "#print(stc_fsave_omi_10_baseline)\n",
    "#print(stc_fsave_omi_8_clfRange)\n",
    "#print(stc_fsave_omi_10_clfRange)\n",
    "print(stc_fsave_omi_8_clfRange.shape)\n",
    "\n",
    "# Compute group-level relative change\n",
    "\n",
    "### 1) Take mean \n",
    "\n",
    "# 80%\n",
    "# take mean over participants (dimension 2)\n",
    "stc_fsave_omi_8_clfRange_avg = np.mean(stc_fsave_omi_8_clfRange, axis=2)\n",
    "print('Shape stc_fsave_omi_8_clfRange_avg after avg over subjects: ', stc_fsave_omi_8_clfRange_avg.shape)\n",
    "# take mean over time points (dimension 1)\n",
    "stc_fsave_omi_8_clfRange_avg= np.mean(stc_fsave_omi_8_clfRange_avg, axis=1)\n",
    "print('Shape stc_fsave_omi_8_clfRange_avg after avg across time: ', stc_fsave_omi_8_clfRange_avg.shape)\n",
    "print('stc_fsave_omi_8_clfRange_avg shape: ', stc_fsave_omi_8_clfRange_avg.shape)\n",
    "\n",
    "print('stc_fsave_omi_8_clfRange_avg: ', stc_fsave_omi_8_clfRange_avg)\n",
    "\n",
    "# take mean over participants (dimension 2)\n",
    "stc_fsave_omi_8_baseline_avg = np.mean(stc_fsave_omi_8_baseline, axis=2)\n",
    "print('Shape stc_fsave_omi_8_baseline_avg after avg over subjects: ', stc_fsave_omi_8_baseline_avg.shape)\n",
    "# take mean over time points (dimension 1)\n",
    "stc_fsave_omi_8_baseline_avg = np.mean(stc_fsave_omi_8_baseline_avg, axis=1)\n",
    "print('Shape stc_fsave_omi_8_baseline_avg after avg across time: ', stc_fsave_omi_8_baseline_avg.shape)\n",
    "print('stc_fsave_omi_8_baseline_avg shape: ', stc_fsave_omi_8_baseline_avg.shape)\n",
    "\n",
    "print('stc_fsave_omi_8_baseline_avg: ', stc_fsave_omi_8_baseline_avg)\n",
    "\n",
    "# 100%\n",
    "# take mean over participants (dimension 2)\n",
    "stc_fsave_omi_10_clfRange_avg = np.mean(stc_fsave_omi_10_clfRange, axis=2)\n",
    "print('Shape stc_fsave_omi_10_clfRange_avg after avg over subjects: ', stc_fsave_omi_10_clfRange_avg.shape)\n",
    "# take mean over time points (dimension 1)\n",
    "stc_fsave_omi_10_clfRange_avg= np.mean(stc_fsave_omi_10_clfRange_avg, axis=1)\n",
    "print('Shape stc_fsave_omi_10_clfRange_avg after avg across time: ', stc_fsave_omi_10_clfRange_avg.shape)\n",
    "print('stc_fsave_omi_10_clfRange_avg shape: ', stc_fsave_omi_10_clfRange_avg.shape)\n",
    "\n",
    "print('stc_fsave_omi_10_clfRange_avg: ', stc_fsave_omi_10_clfRange_avg)\n",
    "\n",
    "# take mean over participants (dimension 2)\n",
    "stc_fsave_omi_10_baseline_avg = np.mean(stc_fsave_omi_10_baseline, axis=2)\n",
    "print('Shape stc_fsave_omi_10_baseline_avg after avg over subjects: ', stc_fsave_omi_10_baseline_avg.shape)\n",
    "# take mean over time points (dimension 1)\n",
    "stc_fsave_omi_10_baseline_avg = np.mean(stc_fsave_omi_10_baseline_avg, axis=1)\n",
    "print('Shape stc_fsave_omi_10_baseline_avg after avg across time: ', stc_fsave_omi_10_baseline_avg.shape)\n",
    "print('stc_fsave_omi_10_baseline_avg shape: ', stc_fsave_omi_10_baseline_avg.shape)\n",
    "\n",
    "print('stc_fsave_omi_10_baseline_avg: ', stc_fsave_omi_10_baseline_avg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### 2) Generate stc group\n",
    "\n",
    "#80%\n",
    "stc_cls_8 = prepareInverseSolution_group(stc_fsave_omi_8_clfRange_avg, subjects_dir, tstep=tstep, tmin_tmp=tminData_cls_tmp)\n",
    "stc_baseline_8 = prepareInverseSolution_group(stc_fsave_omi_8_baseline_avg, subjects_dir, tstep=tstep,\n",
    "                                            tmin_tmp=tminData_baseline_tmp)\n",
    "\n",
    "#100%\n",
    "stc_cls_10 = prepareInverseSolution_group(stc_fsave_omi_10_clfRange_avg, subjects_dir, tstep=tstep, tmin_tmp=tminData_cls_tmp)\n",
    "stc_baseline_10 = prepareInverseSolution_group(stc_fsave_omi_10_baseline_avg, subjects_dir, tstep=tstep,\n",
    "                                            tmin_tmp=tminData_baseline_tmp)\n",
    "\n",
    "### Plot\n",
    "# 80% cls\n",
    "showResult('fsaverage', sourceFolder, stc_cls_8, 'omi_8_clf_'+inv_sol_method+'_sm='+str(smoothAmount), subjects_dir,\n",
    "           minimum=1300000, maximum=3000000)\n",
    "# 80% baseline\n",
    "showResult('fsaverage', sourceFolder, stc_baseline_8, 'omi_8_baseline_'+inv_sol_method+'_sm='+str(smoothAmount),\n",
    "           subjects_dir, minimum=99000, maximum=440000)\n",
    "# 100% cls\n",
    "showResult('fsaverage', sourceFolder, stc_cls_10, 'omi_10_clf_'+inv_sol_method+'_sm='+str(smoothAmount), subjects_dir,\n",
    "           minimum=1300000, maximum=3000000)\n",
    "# 100% baseline\n",
    "showResult('fsaverage', sourceFolder, stc_baseline_10, 'omi_10_baseline_'+inv_sol_method+'_sm='+str(smoothAmount),\n",
    "           subjects_dir, minimum=99000, maximum=440000)\n",
    "\n",
    "### 3) Average relative change\n",
    "\n",
    "#80% avg\n",
    "stc_fsave_omi_8_diff_avg = 100*(stc_fsave_omi_8_clfRange_avg-stc_fsave_omi_8_baseline_avg)/stc_fsave_omi_8_baseline_avg\n",
    "\n",
    "# 100% avg\n",
    "stc_fsave_omi_10_diff_avg = 100*(stc_fsave_omi_10_clfRange_avg-stc_fsave_omi_10_baseline_avg)/stc_fsave_omi_10_baseline_avg\n",
    "\n",
    "print('Minimum of 80%: ', min(stc_fsave_omi_8_diff_avg))\n",
    "print('Maximum of 80%: ', max(stc_fsave_omi_8_diff_avg))\n",
    "\n",
    "print('Minimum of 100%: ', min(stc_fsave_omi_10_diff_avg))\n",
    "print('Maximum of 100%: ', max(stc_fsave_omi_10_diff_avg))\n",
    "\n",
    "thresh_8 = 770 #160\n",
    "thresh_10 = 770\n",
    "print(np.where(stc_fsave_omi_8_diff_avg >thresh_8)[0].shape)\n",
    "print(np.where(stc_fsave_omi_10_diff_avg >thresh_10)[0].shape)\n",
    "\n",
    "## zero out the values below threshold\n",
    "# 80%\n",
    "for i in range(stc_fsave_omi_8_diff_avg.shape[0]):\n",
    "    if stc_fsave_omi_8_diff_avg[i] < thresh_8:\n",
    "        stc_fsave_omi_8_diff_avg[i] = 0\n",
    "        \n",
    "# 100%\n",
    "for i in range(stc_fsave_omi_10_diff_avg.shape[0]):\n",
    "    if stc_fsave_omi_10_diff_avg[i] < thresh_10:\n",
    "        stc_fsave_omi_10_diff_avg[i] = 0\n",
    "\n",
    "stc_diff_8 = prepareInverseSolution_group(stc_fsave_omi_8_diff_avg, subjects_dir, tstep=tstep, tmin_tmp=tminData_cls_tmp)\n",
    "stc_diff_10 = prepareInverseSolution_group(stc_fsave_omi_10_diff_avg, subjects_dir, tstep=tstep, tmin_tmp=tminData_cls_tmp)\n",
    "\n",
    "#### PLOT\n",
    "#80%\n",
    "print('Minimum of 80%: ', min(stc_diff_8.data))\n",
    "print('Maximum of 80%: ', max(stc_diff_8.data))\n",
    "showResult('fsaverage', sourceFolder, stc_diff_8, \n",
    "           '2omi_8_change_'+inv_sol_method+'_sm='+str(smoothAmount) +'_pthresh=' + str(thresh_8), subjects_dir,\n",
    "           minimum=600, maximum=1100)\n",
    "\n",
    "#100%\n",
    "print('Minimum of 100%: ', min(stc_diff_10.data))\n",
    "print('Maximum of 100%: ', max(stc_diff_10.data))\n",
    "showResult('fsaverage', sourceFolder, stc_diff_10, \n",
    "           '2omi_10_change_'+inv_sol_method+'_sm='+str(smoothAmount) +'_pthresh=' + str(thresh_10), subjects_dir,\n",
    "           minimum=600, maximum=1100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute relative change for each participant at 80 and 100 level"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "### 1) Compute relative change\n",
    "\n",
    "#80%\n",
    "# collapse time range by averaging over time points -> output will have the size of n_vertices x nsubjects\n",
    "stc_fsave_omi_8_clfRange_avgOverTime = np.mean(stc_fsave_omi_8_clfRange, axis=1)\n",
    "stc_fsave_omi_8_baseline_avgOverTime = np.mean(stc_fsave_omi_8_baseline, axis=1)\n",
    "\n",
    "stc_fsave_omi_8_diff = np.zeros(stc_fsave_omi_8_clfRange_avgOverTime.shape)\n",
    "print('shape of stc_fsave_omi_8_diff: ', stc_fsave_omi_8_diff.shape)\n",
    "for j in range(stc_fsave_omi_8_diff.shape[1]):\n",
    "    stc_fsave_omi_8_diff[:,j] = 100*(stc_fsave_omi_8_clfRange_avgOverTime[:,j]-stc_fsave_omi_8_baseline_avgOverTime[:,j])/stc_fsave_omi_8_baseline_avgOverTime[:,j]\n",
    "\n",
    "print('stc_fsave_omi_8_diff: ', stc_fsave_omi_8_diff.shape)\n",
    "\n",
    "# 100%\n",
    "# collapse time range by averaging over time points -> output will have the size of n_vertices x nsubjects\n",
    "stc_fsave_omi_10_clfRange_avgOverTime = np.mean(stc_fsave_omi_10_clfRange, axis=1)\n",
    "stc_fsave_omi_10_baseline_avgOverTime = np.mean(stc_fsave_omi_10_baseline, axis=1)\n",
    "\n",
    "stc_fsave_omi_10_diff = np.zeros(stc_fsave_omi_10_clfRange_avgOverTime.shape)\n",
    "\n",
    "for j in range(stc_fsave_omi_10_diff.shape[1]):\n",
    "    stc_fsave_omi_10_diff[:,j] = 100*(stc_fsave_omi_10_clfRange_avgOverTime[:,j]-stc_fsave_omi_10_baseline_avgOverTime[:,j])/stc_fsave_omi_10_baseline_avgOverTime[:,j]\n",
    "\n",
    "print('stc_fsave_omi_10_diff: ', stc_fsave_omi_10_diff)\n",
    "print(stc_fsave_omi_8_diff[0,0])\n",
    "print(stc_fsave_omi_10_diff[0,0])\n",
    "\n",
    "for i in range(stc_fsave_omi_10_diff.shape[1]):\n",
    "    print('i: ', i)\n",
    "    print('N=', len(np.where(stc_fsave_omi_8_diff[:,i]-stc_fsave_omi_10_diff[:,i]>0)[0]))\n",
    "\n",
    "### 2) Stats to contrast 80% predictability and 100% predictability\n",
    "pthresh = 0.05\n",
    "print('computing the stats..')\n",
    "\n",
    "#omissions\n",
    "fvalues_o, pvalues_o = computeStatistic(stc_fsave_omi_10_diff, stc_fsave_omi_8_diff)\n",
    "\n",
    "# save values for omissions\n",
    "fvalue_filename_o = statResultsFolder+'fvalues_all_omi_activations_8vs10_'+inv_sol_method+'_sm='+str(smoothAmount)+'.npy'\n",
    "print(fvalue_filename_o)\n",
    "pvalue_filename_o = statResultsFolder+'pvalues_all_omi_activations_8vs10_'+inv_sol_method+'_sm='+str(smoothAmount)+'.npy'\n",
    "print('saving stats...')\n",
    "np.save(fvalue_filename_o, fvalues_o)\n",
    "np.save(pvalue_filename_o, pvalues_o)\n",
    "\n",
    "print('Significant p vals omi: ', np.where(pvalues_o <= pthresh))\n",
    "fvalues_o_new = np.copy(fvalues_o)\n",
    "pvalues_o_new = np.copy(pvalues_o)\n",
    "\n",
    "for j in range(len(fvalues_o)):\n",
    "    #omissions\n",
    "    if pvalues_o[j] > pthresh:\n",
    "        pvalues_o_new[j] = 1\n",
    "        fvalues_o_new[j] = 0\n",
    "\n",
    "#omissions\n",
    "rejets_o, pvalues_o_corrected = mne.stats.fdr_correction(pvalues_o)\n",
    "print('omissions-corrrected:')\n",
    "print(np.where(pvalues_o_corrected<= pthresh))\n",
    "\n",
    "print('generate stc for stats..')\n",
    "# omissions\n",
    "stc_f_omi = prepareInverseSolution_group(fvalues_o_new, subjects_dir, tstep=tstep)\n",
    "#stc_f_omi = prepareInverseSolution_group(1-pvalues_o_new, subjects_dir, tstep=tstep)\n",
    "\n",
    "#omissions\n",
    "#lateral\n",
    "v_mi, v_ma = 0, 2.09  #-1.5, 1.5\n",
    "showResult('fsaverage', sourceFolder, stc_f_omi, \n",
    "           'pval_predLevel_omi_activations_8vs10_pthresholded_'+inv_sol_method+'_sm='+str(smoothAmount)+'_pthresh='+str(pthresh),\n",
    "           minimum=v_mi, maximum=v_ma, cmap='coolwarm', sequentialCmap=False) #twilight_shifted\n",
    "\n",
    "\n",
    "#del fvalues_o, pvalues_o, pvalues_o_corrected, fvalues_o_new, stc_f_omi\n",
    "\n",
    "print('fvalues_o_new min: ', min(abs(fvalues_o_new[fvalues_o_new != 0])))\n",
    "print('fvalues_o_new max: ', max(abs(fvalues_o_new[fvalues_o_new != 0])))\n",
    "\n",
    "\n",
    "### 3) Compute the difference between 80% and 100%\n",
    "cmap = plt.get_cmap('cmr.seasons')\n",
    "mask = 300\n",
    "\n",
    "stc_fsave_omi_diffBetween_10_8 = np.zeros((stc_fsave_omi_10_diff.shape[0], stc_fsave_omi_10_diff.shape[1]),)\n",
    "for i in range(stc_fsave_omi_10_diff.shape[0]):\n",
    "    for j in range(stc_fsave_omi_10_diff.shape[1]):\n",
    "        stc_fsave_omi_diffBetween_10_8[i,j] = stc_fsave_omi_10_diff[i,j]-stc_fsave_omi_8_diff[i,j]\n",
    "\n",
    "stc_fsave_omi_diffBetween_10_8_avg = np.mean(stc_fsave_omi_diffBetween_10_8, axis=1)\n",
    "stc_fsave_omi_diffBetween_10_8_avg_masked = stc_fsave_omi_diffBetween_10_8_avg.copy()\n",
    "\n",
    "for i in range(stc_fsave_omi_diffBetween_10_8_avg_masked.shape[0]):\n",
    "    if stc_fsave_omi_diffBetween_10_8_avg_masked[i] > 0:\n",
    "        stc_fsave_omi_diffBetween_10_8_avg_masked[i] = 1\n",
    "    else:\n",
    "        stc_fsave_omi_diffBetween_10_8_avg_masked[i] = -1\n",
    "\n",
    "\n",
    "print('Min of stc_fsave_omi_diffBetween_10_8_avg: ', min(stc_fsave_omi_diffBetween_10_8_avg))\n",
    "print('Max of stc_fsave_omi_diffBetween_10_8_avg: ', max(stc_fsave_omi_diffBetween_10_8_avg))\n",
    "\n",
    "stc_fsave_omi_diffBetween_10_8_avg_new = stc_fsave_omi_diffBetween_10_8_avg.copy()\n",
    "for s in range(stc_fsave_omi_diffBetween_10_8_avg_new.shape[0]):\n",
    "    if stc_fsave_omi_diffBetween_10_8_avg[s]  < mask and stc_fsave_omi_diffBetween_10_8_avg[s] > -mask:\n",
    "        stc_fsave_omi_diffBetween_10_8_avg_new[s] = 0\n",
    "        \n",
    "\n",
    "print(len(np.where(stc_fsave_omi_diffBetween_10_8_avg_new < 1)[0]))\n",
    "stc_fsave_omi_diffBetween_10_8_avg_source = prepareInverseSolution_group(stc_fsave_omi_diffBetween_10_8_avg_new,\n",
    "                                                                         subjects_dir, tstep=tstep, tmin_tmp=tminData_cls_tmp)\n",
    "\n",
    "\n",
    "showResult('fsaverage', sourceFolder, stc_fsave_omi_diffBetween_10_8_avg_source, \n",
    "           'omi_diffBetween_10_8_'+inv_sol_method+'_sm='+str(smoothAmount) + 'mask=' + str(mask), \n",
    "           minimum=0, mid=500, maximum=1500, cmap='seismic', sequentialCmap=False)\n",
    "\n",
    "\n",
    "print(stc_fsave_omi_diffBetween_10_8_avg_new[stc_fsave_omi_diffBetween_10_8_avg_new >= 0].shape)\n",
    "print(stc_fsave_omi_diffBetween_10_8_avg_new[stc_fsave_omi_diffBetween_10_8_avg_new < 0].shape)\n",
    "print(stc_fsave_omi_10_diff.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}